{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from per_segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.4])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask_Weights(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.ones(2, 1, requires_grad=True) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_selection(mask_sim, topk=1):\n",
    "    # Top-1 point selection\n",
    "    w, h = mask_sim.shape\n",
    "    topk_xy = mask_sim.flatten(0).topk(topk)[1]\n",
    "    topk_x = (topk_xy // h).unsqueeze(0)\n",
    "    topk_y = (topk_xy - topk_x * h)\n",
    "    topk_xy = torch.cat((topk_y, topk_x), dim=0).permute(1, 0)\n",
    "    topk_label = np.array([1] * topk)\n",
    "    topk_xy = topk_xy.cpu().numpy()\n",
    "    \n",
    "    return topk_xy, topk_label\n",
    "\n",
    "\n",
    "def calculate_dice_loss(inputs, targets, num_masks = 1):\n",
    "    \"\"\"\n",
    "    Compute the DICE loss, similar to generalized IOU for masks\n",
    "    Args:\n",
    "        inputs: A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets: A float tensor with the same shape as inputs. Stores the binary\n",
    "                 classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "    \"\"\"\n",
    "    inputs = inputs.sigmoid()\n",
    "    inputs = inputs.flatten(1)\n",
    "    numerator = 2 * (inputs * targets).sum(-1)\n",
    "    denominator = inputs.sum(-1) + targets.sum(-1)\n",
    "    loss = 1 - (numerator + 1) / (denominator + 1)\n",
    "    return loss.sum() / num_masks\n",
    "\n",
    "\n",
    "def calculate_sigmoid_focal_loss(inputs, targets, num_masks = 1, alpha: float = 0.25, gamma: float = 2):\n",
    "    \"\"\"\n",
    "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
    "    Args:\n",
    "        inputs: A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets: A float tensor with the same shape as inputs. Stores the binary\n",
    "                 classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "        alpha: (optional) Weighting factor in range (0,1) to balance\n",
    "                positive vs negative examples. Default = -1 (no weighting).\n",
    "        gamma: Exponent of the modulating factor (1 - p_t) to\n",
    "               balance easy vs hard examples.\n",
    "    Returns:\n",
    "        Loss tensor\n",
    "    \"\"\"\n",
    "    prob = inputs.sigmoid()\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "    p_t = prob * targets + (1 - prob) * (1 - targets)\n",
    "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
    "\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "\n",
    "    return loss.mean(1).sum() / num_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_folder_path = \"../CFIL_for_NIP/train_data/20250312_demo/ref\"\n",
    "images_folder_path = \"images\"\n",
    "\n",
    "ext = \"jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "train_epoch = 1000\n",
    "log_epoch = 200\n",
    "sam_type = \"vit_h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n------------> Segment \")\n",
    "    \n",
    "# Path preparation\n",
    "ref_image_path = os.path.join(ref_folder_path, f'original.{ext}')\n",
    "ref_mask_path = os.path.join(ref_folder_path, f'mask.{ext}')\n",
    "test_images_path = images_folder_path\n",
    "\n",
    "# Load images and masks\n",
    "ref_image = cv2.imread(ref_image_path)\n",
    "ref_image = cv2.cvtColor(ref_image, cv2.COLOR_BGR2RGB)\n",
    "ref_image = cv2.resize(ref_image,None,fx=0.1,fy=0.1)\n",
    "\n",
    "ref_mask = cv2.imread(ref_mask_path)\n",
    "ref_mask = cv2.cvtColor(ref_mask, cv2.COLOR_BGR2RGB)\n",
    "ref_mask = cv2.resize(ref_mask,None,fx=0.1,fy=0.1)\n",
    "\n",
    "gt_mask = torch.tensor(ref_mask)[:, :, 0] > 0 \n",
    "gt_mask = gt_mask.float().unsqueeze(0).flatten(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"======> Load SAM\" )\n",
    "if sam_type == 'vit_h':\n",
    "    sam_type, sam_ckpt = 'vit_h', '../sam/sam_vit_h.pth'\n",
    "    sam = sam_model_registry[sam_type](checkpoint=sam_ckpt).cuda()\n",
    "elif sam_type == 'vit_t':\n",
    "    sam_type, sam_ckpt = 'vit_t', 'weights/mobile_sam.pt'\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    sam = sam_model_registry[sam_type](checkpoint=sam_ckpt).to(device=device)\n",
    "    sam.eval()\n",
    "\n",
    "\n",
    "for name, param in sam.named_parameters():\n",
    "    param.requires_grad = False\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"======> Obtain Self Location Prior\" )\n",
    "# Image features encoding\n",
    "ref_mask = predictor.set_image(ref_image, ref_mask)\n",
    "ref_feat = predictor.features.squeeze().permute(1, 2, 0)\n",
    "\n",
    "ref_mask = F.interpolate(ref_mask, size=ref_feat.shape[0: 2], mode=\"bilinear\")\n",
    "ref_mask = ref_mask.squeeze()[0]\n",
    "\n",
    "# Target feature extraction\n",
    "target_feat = ref_feat[ref_mask > 0]\n",
    "target_feat_mean = target_feat.mean(0)\n",
    "target_feat_max = torch.max(target_feat, dim=0)[0]\n",
    "target_feat = (target_feat_max / 2 + target_feat_mean / 2).unsqueeze(0)\n",
    "\n",
    "# Cosine similarity\n",
    "h, w, C = ref_feat.shape\n",
    "target_feat = target_feat / target_feat.norm(dim=-1, keepdim=True)\n",
    "ref_feat = ref_feat / ref_feat.norm(dim=-1, keepdim=True)\n",
    "ref_feat = ref_feat.permute(2, 0, 1).reshape(C, h * w)\n",
    "sim = target_feat @ ref_feat\n",
    "\n",
    "sim = sim.reshape(1, 1, h, w)\n",
    "sim = F.interpolate(sim, scale_factor=4, mode=\"bilinear\")\n",
    "sim = predictor.model.postprocess_masks(\n",
    "                sim,\n",
    "                input_size=predictor.input_size,\n",
    "                original_size=predictor.original_size).squeeze()\n",
    "\n",
    "# Positive location prior\n",
    "topk_xy, topk_label = point_selection(sim, topk=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_to_heatmap(sim):\n",
    "    if torch.is_tensor(sim):\n",
    "        x = sim.to(\"cpu\").detach().numpy().copy()\n",
    "    else:\n",
    "        x = sim.copy()\n",
    "    h, w = x.shape\n",
    "    x = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "    x = (x * 255).reshape(-1)\n",
    "    cm = plt.get_cmap(\"jet\")\n",
    "    x = np.array([cm(int(np.round(xi)))[:3] for xi in x])\n",
    "    return (x * 255).astype(np.uint8).reshape(h, w, 3)\n",
    "\n",
    "# heat_map = sim_to_heatmap(sim)\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(heat_map)\n",
    "# plt.axis('on')\n",
    "# plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('======> Start Training')\n",
    "# Learnable mask weights\n",
    "mask_weights = Mask_Weights().cuda()\n",
    "mask_weights.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(mask_weights.parameters(), lr=lr, eps=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_epoch)\n",
    "\n",
    "for train_idx in range(train_epoch):\n",
    "\n",
    "    # Run the decoder\n",
    "    masks, scores, logits, logits_high = predictor.predict(\n",
    "        point_coords=topk_xy,\n",
    "        point_labels=topk_label,\n",
    "        multimask_output=True)\n",
    "    logits_high = logits_high.flatten(1)\n",
    "\n",
    "    # Weighted sum three-scale masks\n",
    "    weights = torch.cat((1 - mask_weights.weights.sum(0).unsqueeze(0), mask_weights.weights), dim=0)\n",
    "    logits_high = logits_high * weights\n",
    "    logits_high = logits_high.sum(0).unsqueeze(0)\n",
    "\n",
    "    dice_loss = calculate_dice_loss(logits_high, gt_mask)\n",
    "    focal_loss = calculate_sigmoid_focal_loss(logits_high, gt_mask)\n",
    "    loss = dice_loss + focal_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if train_idx % log_epoch == 0:\n",
    "        print('Train Epoch: {:} / {:}'.format(train_idx, train_epoch))\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print('LR: {:.6f}, Dice_Loss: {:.4f}, Focal_Loss: {:.4f}'.format(current_lr, dice_loss.item(), focal_loss.item()))\n",
    "\n",
    "\n",
    "mask_weights.eval()\n",
    "weights = torch.cat((1 - mask_weights.weights.sum(0).unsqueeze(0), mask_weights.weights), dim=0)\n",
    "weights_np = weights.detach().cpu().numpy()\n",
    "print('======> Mask weights:\\n', weights_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('======> Start Testing')\n",
    "\n",
    "    # Load test image\n",
    "    # file_name = 'image_almi'\n",
    "folder_path = '../CFIL_for_NIP/train_data/20250312_demo/image'\n",
    "\n",
    "output_path = 'outputs_20250312_demo'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "files = os.listdir(folder_path)\n",
    "for fp in files:\n",
    "    test_image_path = os.path.join(folder_path, fp)\n",
    "    test_image = cv2.imread(test_image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "    test_image = cv2.resize(test_image,None,fx=0.1,fy=0.1)\n",
    "\n",
    "    # Image feature encoding\n",
    "    predictor.set_image(test_image)\n",
    "    test_feat = predictor.features.squeeze()\n",
    "\n",
    "    # Cosine similarity\n",
    "    C, h, w = test_feat.shape\n",
    "    test_feat = test_feat / test_feat.norm(dim=0, keepdim=True)\n",
    "    test_feat = test_feat.reshape(C, h * w)\n",
    "    sim = target_feat @ test_feat\n",
    "\n",
    "    sim = sim.reshape(1, 1, h, w)\n",
    "    sim = F.interpolate(sim, scale_factor=4, mode=\"bilinear\")\n",
    "    sim = predictor.model.postprocess_masks(\n",
    "                    sim,\n",
    "                    input_size=predictor.input_size,\n",
    "                    original_size=predictor.original_size).squeeze()\n",
    "\n",
    "    # Positive location prior\n",
    "    topk_xy, topk_label = point_selection(sim, topk=1)\n",
    "    print(topk_xy, topk_label)\n",
    "\n",
    "    # First-step prediction\n",
    "    masks, scores, logits, logits_high = predictor.predict(\n",
    "                point_coords=topk_xy,\n",
    "                point_labels=topk_label,\n",
    "                multimask_output=True)\n",
    "\n",
    "    # Weighted sum three-scale masks\n",
    "    logits_high = logits_high * weights.unsqueeze(-1)\n",
    "    logit_high = logits_high.sum(0)\n",
    "    mask = (logit_high > 0).detach().cpu().numpy()\n",
    "\n",
    "    logits = logits * weights_np[..., None]\n",
    "    logit = logits.sum(0)\n",
    "\n",
    "    # Cascaded Post-refinement-1\n",
    "    y, x = np.nonzero(mask)\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    y_min = y.min()\n",
    "    y_max = y.max()\n",
    "    input_box = np.array([x_min, y_min, x_max, y_max])\n",
    "    masks, scores, logits, _ = predictor.predict(\n",
    "        point_coords=topk_xy,\n",
    "        point_labels=topk_label,\n",
    "        box=input_box[None, :],\n",
    "        mask_input=logit[None, :, :],\n",
    "        multimask_output=True)\n",
    "    best_idx = np.argmax(scores)\n",
    "\n",
    "    # Cascaded Post-refinement-2\n",
    "    y, x = np.nonzero(masks[best_idx])\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    y_min = y.min()\n",
    "    y_max = y.max()\n",
    "    input_box = np.array([x_min, y_min, x_max, y_max])\n",
    "    masks, scores, logits, _ = predictor.predict(\n",
    "        point_coords=topk_xy,\n",
    "        point_labels=topk_label,\n",
    "        box=input_box[None, :],\n",
    "        mask_input=logits[best_idx: best_idx + 1, :, :],\n",
    "        multimask_output=True)\n",
    "    best_idx = np.argmax(scores)\n",
    "\n",
    "    # Save masks\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(test_image)\n",
    "    show_mask(masks[best_idx], plt.gca())\n",
    "    show_points(topk_xy, topk_label, plt.gca())\n",
    "    plt.title(f\"Mask {best_idx}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    # vis_mask_output_path = os.path.join(output_path, fp)\n",
    "    # with open(vis_mask_output_path, 'wb') as outfile:\n",
    "    #     plt.savefig(outfile, format=ext)\n",
    "    # plt.show()\n",
    "\n",
    "    final_mask = masks[best_idx]\n",
    "    mask_colors = np.zeros((final_mask.shape[0], final_mask.shape[1], 3), dtype=np.uint8)\n",
    "    mask_colors[final_mask, :] = np.array([[0, 0, 128]])\n",
    "    mask_output_path = os.path.join(output_path, f\"masked_{fp}\")\n",
    "    cv2.imwrite(mask_output_path, mask_colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
